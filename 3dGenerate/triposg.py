#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import numpy as np
import torch
from PIL import Image
import trimesh
import random
import gc
import glob
import time
import threading
import queue
import multiprocessing
import psutil
import signal
import subprocess
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FutureTimeoutError

# è®¾ç½®ç¯å¢ƒå˜é‡æ¥é™åˆ¶å¹¶è¡Œå¤„ç†
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["NUMEXPR_NUM_THREADS"] = "1"
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:512,expandable_segments:True"
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DTYPE = torch.float16

print(f"DEVICE: {DEVICE}")
print(f"CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

DEFAULT_FACE_NUMBER = 50000
RMBG_PRETRAINED_MODEL = "checkpoints/RMBG-1.4"
TRIPOSG_PRETRAINED_MODEL = "checkpoints/TripoSG"

TMP_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "output2")
os.makedirs(TMP_DIR, exist_ok=True)

TRIPOSG_CODE_DIR = "./triposg"
MV_ADAPTER_CODE_DIR = "./mv_adapter"

# æ·»åŠ è·¯å¾„
sys.path.append(TRIPOSG_CODE_DIR)
sys.path.append(os.path.join(TRIPOSG_CODE_DIR, "scripts"))
sys.path.append(MV_ADAPTER_CODE_DIR)
sys.path.append(os.path.join(MV_ADAPTER_CODE_DIR, "scripts"))

print("æ­£åœ¨å¯¼å…¥æ¨¡å—...")

try:
    from triposg.pipelines.pipeline_triposg import TripoSGPipeline
    print("âœ… TripoSG pipeline å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ TripoSG pipeline å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from mv_adapter.mvadapter.utils import get_orthogonal_camera, tensor_to_image, make_image_grid
    from mv_adapter.mvadapter.utils.render import NVDiffRastContextWrapper, load_mesh, render
    print("âœ… MV-Adapter utils å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ MV-Adapter utils å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from texture import TexturePipeline, ModProcessConfig
    print("âœ… Texture pipeline å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ Texture pipeline å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from image_process import prepare_image
    print("âœ… Image process å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ Image process å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from inference_ig2mv_sdxl import prepare_pipeline, preprocess_image, remove_bg
    print("âœ… Inference pipeline å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ Inference pipeline å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from briarmbg import BriaRMBG
    print("âœ… BriaRMBG å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ BriaRMBG å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)
    
try:
    from transformers import AutoModelForImageSegmentation
    from torchvision import transforms
    print("âœ… Transformers å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ Transformers å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

class ThreadTimeoutError(Exception):
    """çº¿ç¨‹è¶…æ—¶å¼‚å¸¸"""
    pass

class ProcessKiller:
    """è¿›ç¨‹ç»ˆæ­¢å™¨ï¼Œç”¨äºå¼ºåˆ¶ç»ˆæ­¢å­è¿›ç¨‹"""
    def __init__(self):
        self.processes = []
    
    def add_process(self, process):
        self.processes.append(process)
    
    def kill_all(self):
        """å¼ºåˆ¶ç»ˆæ­¢æ‰€æœ‰è¿›ç¨‹"""
        for proc in self.processes:
            try:
                if proc.poll() is None:  # è¿›ç¨‹è¿˜åœ¨è¿è¡Œ
                    proc.terminate()
                    proc.wait(timeout=5)
            except:
                try:
                    proc.kill()
                except:
                    pass
        self.processes.clear()

def run_with_thread_timeout(func, args=(), kwargs=None, timeout_seconds=120):
    """
    åœ¨çº¿ç¨‹ä¸­è¿è¡Œå‡½æ•°ï¼Œå¦‚æœè¶…æ—¶åˆ™å¼ºåˆ¶é€€å‡º
    """
    if kwargs is None:
        kwargs = {}
    
    result_queue = queue.Queue()
    exception_queue = queue.Queue()
    
    def target():
        try:
            result = func(*args, **kwargs)
            result_queue.put(result)
        except Exception as e:
            exception_queue.put(e)
    
    thread = threading.Thread(target=target)
    thread.daemon = True  # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹
    thread.start()
    
    # ç­‰å¾…ç»“æœæˆ–è¶…æ—¶
    thread.join(timeout=timeout_seconds)
    
    if thread.is_alive():
        # çº¿ç¨‹ä»åœ¨è¿è¡Œï¼Œè¯´æ˜è¶…æ—¶äº†
        print(f"â° æ“ä½œè¶…æ—¶ ({timeout_seconds}ç§’)ï¼Œå¼ºåˆ¶ç»ˆæ­¢...")
        # æ³¨æ„ï¼šPythonä¸­æ— æ³•ç›´æ¥ç»ˆæ­¢çº¿ç¨‹ï¼Œä½†å®ˆæŠ¤çº¿ç¨‹ä¼šåœ¨ä¸»ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨ç»ˆæ­¢
        raise ThreadTimeoutError(f"æ“ä½œè¶…æ—¶ ({timeout_seconds}ç§’)")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸
    if not exception_queue.empty():
        raise exception_queue.get()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœ
    if not result_queue.empty():
        return result_queue.get()
    
    raise ThreadTimeoutError("æ“ä½œæœªè¿”å›ç»“æœ")

def run_texture_with_subprocess(mesh_path, save_dir, save_name, uv_size, rgb_path, base_name, timeout_seconds=120):
    """
    ä½¿ç”¨å­è¿›ç¨‹è¿è¡Œçº¹ç†å¤„ç†ï¼Œå¯ä»¥å¼ºåˆ¶ç»ˆæ­¢
    """
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„Pythonè„šæœ¬æ¥æ‰§è¡Œçº¹ç†å¤„ç†
    temp_script = os.path.join(TMP_DIR, f"temp_texture_{base_name}.py")
    
    script_content = f'''
import sys
import os
sys.path.append("./triposg")
sys.path.append("./mv_adapter")
import torch
from texture import TexturePipeline, ModProcessConfig

try:
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    
    texture_pipe = TexturePipeline(
        upscaler_ckpt_path="checkpoints/RealESRGAN_x2plus.pth",
        inpaint_ckpt_path="checkpoints/big-lama.pt",
        device=DEVICE,
    )
    
    result = texture_pipe(
        mesh_path="{mesh_path}",
        save_dir="{save_dir}",
        save_name="{save_name}",
        uv_unwarp=True,
        uv_size={uv_size},
        rgb_path="{rgb_path}",
        rgb_process_config=ModProcessConfig(
            view_upscale={uv_size >= 2048},
            inpaint_mode="view"
        ),
        camera_azimuth_deg=[x - 90 for x in [0, 90, 180, 270, 180, 180]],
    )
    
    print(f"SUCCESS:{{result.shaded_model_save_path if hasattr(result, 'shaded_model_save_path') else str(result)}}")
    
except Exception as e:
    print(f"ERROR:{{str(e)}}")
    import traceback
    traceback.print_exc()
'''
    
    # å†™å…¥ä¸´æ—¶è„šæœ¬
    with open(temp_script, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    try:
        # å¯åŠ¨å­è¿›ç¨‹
        process = subprocess.Popen(
            [sys.executable, temp_script],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            preexec_fn=os.setsid  # åˆ›å»ºæ–°çš„è¿›ç¨‹ç»„
        )
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆæˆ–è¶…æ—¶
        try:
            stdout, stderr = process.communicate(timeout=timeout_seconds)
            
            # è§£æè¾“å‡º
            if "SUCCESS:" in stdout:
                result_path = stdout.split("SUCCESS:")[1].strip()
                return result_path
            elif "ERROR:" in stdout:
                error_msg = stdout.split("ERROR:")[1].strip()
                raise Exception(f"å­è¿›ç¨‹é”™è¯¯: {error_msg}")
            else:
                raise Exception(f"å­è¿›ç¨‹æœªè¿”å›é¢„æœŸç»“æœ: {stdout}")
                
        except subprocess.TimeoutExpired:
            print(f"â° çº¹ç†å¤„ç†è¶…æ—¶ ({timeout_seconds}ç§’)ï¼Œå¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹...")
            
            # å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹ç»„
            try:
                os.killpg(os.getpgid(process.pid), signal.SIGTERM)
                time.sleep(2)
                if process.poll() is None:
                    os.killpg(os.getpgid(process.pid), signal.SIGKILL)
            except:
                pass
            
            process.kill()
            process.wait()
            raise ThreadTimeoutError(f"çº¹ç†å¤„ç†è¶…æ—¶ ({timeout_seconds}ç§’)")
            
    finally:
        # æ¸…ç†ä¸´æ—¶è„šæœ¬
        try:
            os.remove(temp_script)
        except:
            pass

def force_cleanup_memory():
    """å¼ºåˆ¶æ¸…ç†GPUå’ŒCPUå†…å­˜"""
    try:
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
        if torch.cuda.is_available():
            torch.cuda.reset_peak_memory_stats()
    except:
        pass
    gc.collect()
    
    # æ‰“å°å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        cached = torch.cuda.memory_reserved() / 1024**3
        print(f"  ğŸ’¾ GPUå†…å­˜: å·²åˆ†é… {allocated:.2f}GB, å·²ç¼“å­˜ {cached:.2f}GB")

def repair_mesh_for_uv(mesh):
    """å¼ºåŠ›ä¿®å¤ç½‘æ ¼ï¼Œç¡®ä¿å¯ä»¥è¿›è¡ŒUVå±•å¼€"""
    print("    æ­£åœ¨å¼ºåŠ›ä¿®å¤ç½‘æ ¼ä»¥æ”¯æŒUVå±•å¼€...")
    try:
        # æ­¥éª¤1: åŸºç¡€æ¸…ç†
        mesh.update_faces(mesh.unique_faces())
        
        # æ­¥éª¤2: ä¿®å¤æ³•çº¿
        mesh.fix_normals()
        
        # æ­¥éª¤3: å¡«å……å°å­”æ´
        mesh.fill_holes()
        
        # æ­¥éª¤4: åˆ†ç¦»è¿é€šç»„ä»¶ï¼Œä¿ç•™æœ€å¤§çš„
        components = mesh.split(only_watertight=False)
        if len(components) > 1:
            print(f"      å‘ç°{len(components)}ä¸ªè¿é€šç»„ä»¶ï¼Œä¿ç•™æœ€å¤§çš„")
            mesh = max(components, key=lambda x: len(x.vertices))
        
        # æ­¥éª¤5: å¼ºåˆ¶ä½¿ç½‘æ ¼æˆä¸ºæµå½¢
        try:
            if not mesh.is_watertight:
                mesh.remove_unreferenced_vertices()
                
                if not mesh.is_watertight:
                    convex_mesh = mesh.convex_hull
                    if convex_mesh.is_watertight:
                        mesh = convex_mesh
        except Exception as e:
            print(f"      æµå½¢åŒ–è¿‡ç¨‹ä¸­å‡ºç°è­¦å‘Š: {e}")
        
        print(f"      ç½‘æ ¼ä¿®å¤å®Œæˆ - é¡¶ç‚¹: {len(mesh.vertices)}, é¢: {len(mesh.faces)}, æ°´å¯†: {mesh.is_watertight}")
        return mesh
        
    except Exception as e:
        print(f"      ç½‘æ ¼ä¿®å¤å¤±è´¥: {e}")
        return mesh

class TripoSGBatchProcessor:
    def __init__(self):
        self.rmbg_net = None
        self.triposg_pipe = None
        self.mv_adapter_pipe = None
        self.remove_bg_fn = None
        self.texture_pipe = None
        self.NUM_VIEWS = 6
        self.process_killer = ProcessKiller()
        
    def setup_models(self):
        """ä¸€æ¬¡æ€§åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹"""
        print("æ­£åœ¨åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹...")
        
        # åˆå§‹åŒ–å‰å…ˆæ¸…ç†å†…å­˜
        force_cleanup_memory()
        
        # RMBGæ¨¡å‹
        print("  æ­£åœ¨åˆå§‹åŒ–RMBGæ¨¡å‹...")
        if os.path.exists(RMBG_PRETRAINED_MODEL):
            self.rmbg_net = BriaRMBG.from_pretrained(RMBG_PRETRAINED_MODEL).to(DEVICE)
            self.rmbg_net.eval()
            print("  âœ… RMBGæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        else:
            print(f"  âŒ RMBGæ¨¡å‹æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {RMBG_PRETRAINED_MODEL}")
            return False
        
        # TripoSGæ¨¡å‹
        print("  æ­£åœ¨åˆå§‹åŒ–TripoSGæ¨¡å‹...")
        if os.path.exists(TRIPOSG_PRETRAINED_MODEL):
            self.triposg_pipe = TripoSGPipeline.from_pretrained(TRIPOSG_PRETRAINED_MODEL).to(DEVICE, DTYPE)
            print("  âœ… TripoSGæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        else:
            print(f"  âŒ TripoSGæ¨¡å‹æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {TRIPOSG_PRETRAINED_MODEL}")
            return False
        
        # MV-Adapter
        print("  æ­£åœ¨åˆå§‹åŒ–MV-Adapter...")
        os.environ["HF_HUB_OFFLINE"] = "1"
        self.mv_adapter_pipe = prepare_pipeline(
            base_model="stabilityai/stable-diffusion-xl-base-1.0",
            vae_model="madebyollin/sdxl-vae-fp16-fix",
            unet_model=None,
            lora_model=None,
            adapter_path="huanngzh/mv-adapter",
            scheduler=None,
            num_views=self.NUM_VIEWS,
            device=DEVICE,
            dtype=torch.float16,
        )
        print("  âœ… MV-Adapteråˆå§‹åŒ–å®Œæˆ")
        
        # BiRefNet
        print("  æ­£åœ¨åˆå§‹åŒ–BiRefNet...")
        birefnet = AutoModelForImageSegmentation.from_pretrained(
            "ZhengPeng7/BiRefNet", trust_remote_code=True
        )
        birefnet.to(DEVICE)
        transform_image = transforms.Compose([
            transforms.Resize((1024, 1024)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ])
        self.remove_bg_fn = lambda x: remove_bg(x, birefnet, transform_image, DEVICE)
        print("  âœ… BiRefNetåˆå§‹åŒ–å®Œæˆ")
        
        # çº¹ç†ç®¡é“åˆå§‹åŒ–æ¨è¿Ÿåˆ°ä½¿ç”¨æ—¶ï¼ˆå› ä¸ºå®¹æ˜“å¡æ­»ï¼‰
        print("  ğŸ“ çº¹ç†ç®¡é“å°†åœ¨ä½¿ç”¨æ—¶åˆå§‹åŒ–")
        
        print("ğŸ‰ æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼")
        return True
    
    def generate_3d_mesh(self, image_seg, seed=0):
        """ç”Ÿæˆ3Dç½‘æ ¼ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰"""
        def _generate():
            num_inference_steps = 20
            guidance_scale = 7.5
            
            outputs = self.triposg_pipe(
                image=image_seg,
                generator=torch.Generator(device=self.triposg_pipe.device).manual_seed(seed),
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale
            ).samples[0]
            
            # ç¡®ä¿outputsæ˜¯æ­£ç¡®çš„æ ¼å¼
            if isinstance(outputs, tuple) and len(outputs) >= 2:
                vertices, faces = outputs[0], outputs[1]
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                if hasattr(vertices, 'cpu'):
                    vertices = vertices.cpu().numpy()
                if hasattr(faces, 'cpu'):
                    faces = faces.cpu().numpy()
                mesh = trimesh.Trimesh(vertices.astype(np.float32), np.ascontiguousarray(faces))
                return mesh
            else:
                raise Exception("TripoSGè¾“å‡ºæ ¼å¼ä¸æ­£ç¡®")
        
        return run_with_thread_timeout(_generate, timeout_seconds=90)
    
    def generate_multiview_images(self, mesh_path, reference_image, seed=0):
        """ç”Ÿæˆå¤šè§†è§’å›¾åƒï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰"""
        def _generate():
            height, width = 768, 768
            
            cameras = get_orthogonal_camera(
                elevation_deg=[0, 0, 0, 0, 89.99, -89.99],
                distance=[1.8] * self.NUM_VIEWS,
                left=-0.55,
                right=0.55,
                bottom=-0.55,
                top=0.55,
                azimuth_deg=[x - 90 for x in [0, 90, 180, 270, 180, 180]],
                device=DEVICE,
            )
            
            # æ¸²æŸ“æ§åˆ¶å›¾åƒ
            ctx = NVDiffRastContextWrapper(device=DEVICE, context_type="cuda")
            mesh_render = load_mesh(mesh_path, rescale=True, device=DEVICE)
            render_out = render(
                ctx,
                mesh_render,
                cameras,
                height=height,
                width=width,
                render_attr=False,
                normal_background=0.0,
            )
            
            if render_out is None or not hasattr(render_out, 'pos') or not hasattr(render_out, 'normal'):
                raise Exception("æ¸²æŸ“è¾“å‡ºæ— æ•ˆ")
            
            control_images = (
                torch.cat([
                    (render_out.pos + 0.5).clamp(0, 1),
                    (render_out.normal / 2 + 0.5).clamp(0, 1),
                ], dim=-1,)
                .permute(0, 3, 1, 2)
                .to(DEVICE)
            )
            
            # æ¸…ç†æ¸²æŸ“èµ„æº
            del render_out, mesh_render, cameras, ctx
            force_cleanup_memory()
            
            # ç”Ÿæˆå¤šè§†è§’å›¾åƒ
            pipe_kwargs = {"generator": torch.Generator(device=DEVICE).manual_seed(seed)}
            
            try:
                images = self.mv_adapter_pipe(
                    "high quality",
                    height=height,
                    width=width,
                    num_inference_steps=15,
                    guidance_scale=3.0,
                    num_images_per_prompt=self.NUM_VIEWS,
                    control_image=control_images,
                    control_conditioning_scale=1.0,
                    reference_image=reference_image,
                    reference_conditioning_scale=1.0,
                    negative_prompt="watermark, ugly, deformed, noisy, blurry, low contrast",
                    cross_attention_kwargs={"scale": 1.0},
                    **pipe_kwargs,
                ).images
                
                if images is None:
                    raise Exception("MV-Adapterè¿”å›äº†None")
                
                return images
                
            except torch.cuda.OutOfMemoryError:
                print("  å†…å­˜ä¸è¶³ï¼Œåˆ‡æ¢åˆ°åˆ†æ‰¹å¤„ç†æ¨¡å¼...")
                force_cleanup_memory()
                
                # åˆ†æ‰¹å¤„ç†
                images = []
                batch_size = 3
                
                for batch_start in range(0, self.NUM_VIEWS, batch_size):
                    batch_end = min(batch_start + batch_size, self.NUM_VIEWS)
                    batch_control = control_images[batch_start:batch_end]
                    
                    batch_images = self.mv_adapter_pipe(
                        "high quality",
                        height=height,
                        width=width,
                        num_inference_steps=15,
                        guidance_scale=3.0,
                        num_images_per_prompt=batch_end - batch_start,
                        control_image=batch_control,
                        control_conditioning_scale=1.0,
                        reference_image=reference_image,
                        reference_conditioning_scale=1.0,
                        negative_prompt="watermark, ugly, deformed, noisy, blurry, low contrast",
                        cross_attention_kwargs={"scale": 1.0},
                        **pipe_kwargs,
                    ).images
                    
                    if batch_images is None:
                        raise Exception("MV-Adapteræ‰¹æ¬¡è¿”å›äº†None")
                    
                    images.extend(batch_images)
                    
                    # æ¸…ç†æ‰¹æ¬¡å†…å­˜
                    del batch_control, batch_images
                    force_cleanup_memory()
                
                return images
        
        return run_with_thread_timeout(_generate, timeout_seconds=120)
    
    def apply_texture_with_timeout(self, mesh_path, base_name, mv_image_path):
        """åº”ç”¨çº¹ç†ï¼ˆå¸¦ä¸¥æ ¼è¶…æ—¶æ§åˆ¶ï¼‰"""
        print("æ­¥éª¤4: æ­£åœ¨åº”ç”¨çº¹ç†...")
        
        textured_path = mesh_path  # é»˜è®¤å€¼
        
        # å°è¯•ä¸åŒçš„UVåˆ†è¾¨ç‡ï¼Œä½¿ç”¨å­è¿›ç¨‹æ‰§è¡Œ
        for uv_size, strategy_name, timeout_sec in [(4096, "4K", 120), (2048, "2K", 90), (1024, "1K", 60)]:
            try:
                print(f"  å°è¯•{strategy_name}åˆ†è¾¨ç‡UVå±•å¼€... (è¶…æ—¶: {timeout_sec}ç§’)")
                
                save_name = f"{base_name}_textured_{strategy_name.lower()}.glb"
                
                # ä½¿ç”¨å­è¿›ç¨‹å¤„ç†çº¹ç†
                result_path = run_texture_with_subprocess(
                    mesh_path=mesh_path,
                    save_dir=TMP_DIR,
                    save_name=save_name,
                    uv_size=uv_size,
                    rgb_path=mv_image_path,
                    base_name=base_name,
                    timeout_seconds=timeout_sec
                )
                
                print(f"  âœ… {strategy_name}çº¹ç†åº”ç”¨æˆåŠŸ!")
                textured_path = result_path
                break
                
            except ThreadTimeoutError as e:
                print(f"  â° {strategy_name}çº¹ç†åº”ç”¨è¶…æ—¶: {e}")
                if uv_size == 1024:  # æœ€åä¸€æ¬¡å°è¯•
                    print("  âŒ æ‰€æœ‰çº¹ç†ç­–ç•¥éƒ½è¶…æ—¶ï¼Œä½¿ç”¨åŸºç¡€ç½‘æ ¼")
                    textured_path = mesh_path
            except Exception as e:
                print(f"  âŒ {strategy_name}çº¹ç†åº”ç”¨å¤±è´¥: {e}")
                if uv_size == 1024:  # æœ€åä¸€æ¬¡å°è¯•
                    print("  âŒ æ‰€æœ‰çº¹ç†ç­–ç•¥éƒ½å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ç½‘æ ¼")
                    textured_path = mesh_path
            finally:
                # å¼ºåˆ¶æ¸…ç†å†…å­˜
                force_cleanup_memory()
        
        return textured_path
    
    def process_single_image(self, image_path, base_name):
        """å¤„ç†å•å¼ å›¾ç‰‡"""
        print(f"\n{'='*60}")
        print(f"å¼€å§‹å¤„ç†: {image_path}")
        print(f"è¾“å‡ºå‰ç¼€: {base_name}")
        print(f"{'='*60}")
        
        # å¼€å§‹å‰å…ˆæ¸…ç†ä¸€æ¬¡å†…å­˜
        force_cleanup_memory()
        
        try:
            # ä½¿ç”¨5åˆ†é’Ÿæ€»è¶…æ—¶
            return run_with_thread_timeout(
                self._process_single_image_internal,
                args=(image_path, base_name),
                timeout_seconds=300  # 5åˆ†é’Ÿ
            )
            
        except ThreadTimeoutError:
            print(f"\nâ° {base_name} æ€»å¤„ç†è¶…æ—¶ (5åˆ†é’Ÿ)ï¼Œå¼ºåˆ¶è·³è¿‡")
            # å¼ºåˆ¶ç»ˆæ­¢æ‰€æœ‰å­è¿›ç¨‹
            self.process_killer.kill_all()
            force_cleanup_memory()
            return {'success': False, 'error': 'æ€»å¤„ç†è¶…æ—¶ (5åˆ†é’Ÿ)'}
        except Exception as e:
            print(f"\nâŒ {base_name} å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # å¤±è´¥æ—¶æ¸…ç†èµ„æº
            self.process_killer.kill_all()
            force_cleanup_memory()
            
            return {'success': False, 'error': str(e)}
    
    def _process_single_image_internal(self, image_path, base_name):
        """å†…éƒ¨å¤„ç†å•å¼ å›¾ç‰‡çš„å®é™…é€»è¾‘"""
        try:
            # æ­¥éª¤1: å›¾åƒåˆ†å‰²
            print("æ­¥éª¤1: æ­£åœ¨è¿›è¡Œå›¾åƒåˆ†å‰²...")
            image_seg = prepare_image(image_path, bg_color=np.array([1.0, 1.0, 1.0]), rmbg_net=self.rmbg_net)
            
            if image_seg is None:
                raise Exception("å›¾åƒåˆ†å‰²å¤±è´¥ï¼Œè¿”å›äº†None")
            
            seg_save_path = os.path.join(TMP_DIR, f"{base_name}_segmented.png")
            image_seg.save(seg_save_path)
            print(f"  âœ… åˆ†å‰²å®Œæˆ: {seg_save_path}")
            
            # æ­¥éª¤2: ç”Ÿæˆ3Dç½‘æ ¼
            print("æ­¥éª¤2: æ­£åœ¨ç”Ÿæˆ3Dç½‘æ ¼...")
            mesh = self.generate_3d_mesh(image_seg)
            
            # æ¸…ç†GPUå†…å­˜
            force_cleanup_memory()
            
            # ä¿®å¤ç½‘æ ¼
            mesh = repair_mesh_for_uv(mesh)
            
            # ç®€åŒ–ç½‘æ ¼
            print("  æ­£åœ¨ç®€åŒ–ç½‘æ ¼...")
            try:
                from utils import simplify_mesh
                mesh = simplify_mesh(mesh, DEFAULT_FACE_NUMBER)
                mesh = repair_mesh_for_uv(mesh)
            except Exception as e:
                print(f"  è­¦å‘Š: ç½‘æ ¼ç®€åŒ–å¤±è´¥: {e}")
            
            mesh_path = os.path.join(TMP_DIR, f"{base_name}_mesh.glb")
            mesh.export(mesh_path)
            print(f"  âœ… ç½‘æ ¼ç”Ÿæˆå®Œæˆ: {mesh_path}")
            
            # æ­¥éª¤3: ç”Ÿæˆå¤šè§†è§’å›¾åƒ
            print("æ­¥éª¤3: æ­£åœ¨ç”Ÿæˆå¤šè§†è§’å›¾åƒ...")
            
            # å‡†å¤‡å‚è€ƒå›¾åƒ
            image = Image.open(image_path)
            if self.remove_bg_fn is None:
                raise Exception("èƒŒæ™¯ç§»é™¤å‡½æ•°æœªåˆå§‹åŒ–")
            image = self.remove_bg_fn(image)
            image = preprocess_image(image, 768, 768)
            
            # ç”Ÿæˆå¤šè§†è§’å›¾åƒ
            images = self.generate_multiview_images(mesh_path, image)
            
            # æ¸…ç†å†…å­˜
            del image
            force_cleanup_memory()
            
            mv_image_path = os.path.join(TMP_DIR, f"{base_name}_multiview.png")
            make_image_grid(images, rows=1).save(mv_image_path)
            print(f"  âœ… å¤šè§†è§’å›¾åƒç”Ÿæˆå®Œæˆ: {mv_image_path}")
            
            # æ¸…ç†images
            del images
            force_cleanup_memory()
            
            # æ­¥éª¤4: åº”ç”¨çº¹ç†ï¼ˆä½¿ç”¨å¼ºåˆ¶è¶…æ—¶æ§åˆ¶ï¼‰
            textured_path = self.apply_texture_with_timeout(mesh_path, base_name, mv_image_path)
            
            print(f"\nğŸ‰ {base_name} å¤„ç†å®Œæˆ!")
            print(f"ğŸ“ åˆ†å‰²å›¾åƒ: {seg_save_path}")
            print(f"ğŸ“ ç½‘æ ¼æ–‡ä»¶: {mesh_path}")
            print(f"ğŸ“ å¤šè§†è§’å›¾åƒ: {mv_image_path}")
            print(f"ğŸ“ æœ€ç»ˆæ¨¡å‹: {textured_path}")
            
            return {
                'success': True,
                'segmented': seg_save_path,
                'mesh': mesh_path,
                'multiview': mv_image_path,
                'textured': textured_path
            }
            
        except Exception as e:
            raise e
    
    def process_batch(self, input_dir):
        """æ‰¹å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
        # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']
        image_files = []
        
        for ext in image_extensions:
            image_files.extend(glob.glob(os.path.join(input_dir, ext)))
        
        if not image_files:
            print(f"âŒ åœ¨ {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return
        
        print(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶:")
        for img in image_files:
            print(f"  - {os.path.basename(img)}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        if not self.setup_models():
            print("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
            return
        
        # å¤„ç†æ¯å¼ å›¾ç‰‡
        results = []
        for i, image_path in enumerate(image_files, 1):
            base_name = os.path.splitext(os.path.basename(image_path))[0]
            
            print(f"\n{'#'*80}")
            print(f"å¤„ç†è¿›åº¦: {i}/{len(image_files)} - {base_name}")
            print(f"{'#'*80}")
            
            # å¤„ç†å‰å¼ºåˆ¶æ¸…ç†å†…å­˜
            force_cleanup_memory()
            
            result = self.process_single_image(image_path, base_name)
            result['image_path'] = image_path
            result['base_name'] = base_name
            results.append(result)
            
            # å¤„ç†åå¼ºåˆ¶æ¸…ç†å†…å­˜å’Œè¿›ç¨‹
            self.process_killer.kill_all()
            force_cleanup_memory()
            
            # æ¯å¤„ç†3å¼ å›¾ç‰‡é¢å¤–æ¸…ç†ä¸€æ¬¡
            if i % 3 == 0:
                print(f"  ğŸ“Š å·²å¤„ç†{i}å¼ å›¾ç‰‡ï¼Œæ‰§è¡Œæ·±åº¦æ¸…ç†...")
                time.sleep(3)  # ç­‰å¾…3ç§’è®©æ‰€æœ‰èµ„æºå®Œå…¨é‡Šæ”¾
                force_cleanup_memory()
                
                # æ£€æŸ¥å¹¶æ‰“å°å†…å­˜ç»Ÿè®¡
                if torch.cuda.is_available():
                    max_memory = torch.cuda.max_memory_allocated() / 1024**3
                    print(f"  ğŸ“ˆ å³°å€¼GPUå†…å­˜ä½¿ç”¨: {max_memory:.2f}GB")
                    torch.cuda.reset_peak_memory_stats()
        
        # è¾“å‡ºæ€»ç»“
        print(f"\n{'='*80}")
        print("æ‰¹å¤„ç†å®Œæˆæ€»ç»“:")
        print(f"{'='*80}")
        
        success_count = sum(1 for r in results if r['success'])
        print(f"æˆåŠŸå¤„ç†: {success_count}/{len(results)}")
        
        for result in results:
            if result['success']:
                print(f"âœ… {result['base_name']}")
                print(f"   åˆ†å‰²å›¾åƒ: {result['segmented']}")
                print(f"   ç½‘æ ¼æ–‡ä»¶: {result['mesh']}")
                print(f"   å¤šè§†è§’å›¾åƒ: {result['multiview']}")
                print(f"   æœ€ç»ˆæ¨¡å‹: {result['textured']}")
            else:
                print(f"âŒ {result['base_name']}: {result['error']}")
        
        print(f"\nğŸ‰ æ‰¹å¤„ç†å®Œæˆ! æˆåŠŸç‡: {success_count}/{len(results)}")

def main():
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python triposg_batch_threaded.py <è¾“å…¥ç›®å½•>")
        print("ç¤ºä¾‹: python triposg_batch_threaded.py test/")
        sys.exit(1)
    
    input_dir = sys.argv[1]
    if not os.path.exists(input_dir):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥ç›®å½• {input_dir}")
        sys.exit(1)
    
    processor = TripoSGBatchProcessor()
    processor.process_batch(input_dir)

if __name__ == "__main__":
    main()