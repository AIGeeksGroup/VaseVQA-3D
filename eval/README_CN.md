# VaseVQA-3D è¯„ä¼°æ¨¡å—

æœ¬ç›®å½•åŒ…å« VaseVQA-3D é¡¹ç›®çš„è¯„ä¼°ç›¸å…³ä»£ç ï¼Œä¸»è¦ç”¨äºç”Ÿæˆå¤šè§†è§’å›¾åƒçš„æè¿°ï¼ˆCaptionï¼‰å¹¶è¯„ä¼°ç”Ÿæˆè´¨é‡ã€‚

## ğŸ“ ç›®å½•ç»“æ„

```
eval/
â”œâ”€â”€ qwen.py                # Qwen2.5-VLå¤šè§†è§’æè¿°ç”Ÿæˆå™¨
â”œâ”€â”€ internvl.py            # InternVLå¤šè§†è§’æè¿°ç”Ÿæˆå™¨
â”œâ”€â”€ compare.py             # Captionè¯„ä¼°è„šæœ¬
â”œâ”€â”€ compare.sh             # æ‰¹é‡è¯„ä¼°è„šæœ¬
â””â”€â”€ README.md              # æœ¬æ–‡æ¡£
```

---

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

è¯„ä¼°æ¨¡å—åŒ…å«ä¸¤ä¸ªä¸»è¦åŠŸèƒ½ï¼š

1. **Caption ç”Ÿæˆ**ï¼šä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆQwen2.5-VL æˆ– InternVLï¼‰ä¸ºå¤šè§†è§’å›¾åƒç”Ÿæˆæè¿°
2. **Caption è¯„ä¼°**ï¼šä½¿ç”¨å¤šç§æŒ‡æ ‡è¯„ä¼°ç”Ÿæˆçš„æè¿°è´¨é‡

---

## ğŸ“ Caption ç”Ÿæˆ

### 1. Qwen2.5-VL æè¿°ç”Ÿæˆå™¨

**æ–‡ä»¶ï¼š** `qwen.py`

**åŠŸèƒ½ï¼š** åŸºäº Qwen2.5-VL æ¨¡å‹ï¼Œåˆ†æå¤šè§†è§’å›¾åƒå¹¶ç”Ÿæˆç»¼åˆæè¿°

#### ä½¿ç”¨æ–¹æ³•

**æ‰¹é‡å¤„ç†ï¼š**
```bash
python qwen.py --input_dir ./data/multiview_images \
               --output_dir ./data/captions \
               --model_path ./models/Qwen2.5-VL-3B-Instruct
```

**å¤„ç†å•ä¸ªæ¨¡å‹ï¼š**
```bash
python qwen.py --single_model ./data/multiview_images/model1 \
               --output_dir ./data/captions \
               --model_path ./models/Qwen2.5-VL-7B-Instruct
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--input_dir` | åŒ…å«å¤šè§†è§’å›¾ç‰‡çš„è¾“å…¥ç›®å½• | `./data/multiview_images` |
| `--output_dir` | æè¿°è¾“å‡ºç›®å½• | `./data/captions` |
| `--model_path` | Qwen2.5-VLæ¨¡å‹è·¯å¾„ | `./models/Qwen2.5-VL-3B-Instruct` |
| `--single_model` | å¤„ç†å•ä¸ªæ¨¡å‹ç›®å½•ï¼ˆå¯é€‰ï¼‰ | `None` |

#### è¾“å…¥æ•°æ®æ ¼å¼

å¤šè§†è§’å›¾ç‰‡ç›®å½•ç»“æ„ï¼š
```
multiview_images/
â”œâ”€â”€ UUID_1_ac001001_textured_4k.glb_shaded/
â”‚   â”œâ”€â”€ front.jpg
â”‚   â”œâ”€â”€ back.jpg
â”‚   â”œâ”€â”€ left.jpg
â”‚   â”œâ”€â”€ right.jpg
â”‚   â”œâ”€â”€ top.jpg
â”‚   â””â”€â”€ bottom.jpg
â”œâ”€â”€ UUID_2_ac001001_textured_4k.glb_shaded/
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

#### è¾“å‡ºæ ¼å¼

ç”Ÿæˆçš„ JSON æ–‡ä»¶æ ¼å¼ï¼š
```json
[
  {
    "images": ["UUID_1_ac001001.jpg"],
    "caption": "Athenian black-figure lekythos, c. 525â€“475 BCE, depicting Herakles and the boar; Marathon, Attica.",
    "data_by": "qwen2.5"
  },
  {
    "images": ["UUID_2_ac001001.jpg"],
    "caption": "...",
    "data_by": "qwen2.5"
  }
]
```

è¾“å‡ºæ–‡ä»¶ï¼š
- `image_qwen2.5-vl-3B-sft.json` - ç”Ÿæˆçš„æè¿°
- `qwen2.5_caption_generation_report.json` - å¤„ç†æŠ¥å‘Š

#### æç¤ºè¯æ¨¡æ¿

è„šæœ¬ä½¿ç”¨ä»¥ä¸‹æç¤ºè¯å¼•å¯¼æ¨¡å‹ç”Ÿæˆæè¿°ï¼š

```
è¯·åˆ†æè¿™ä¸ªå¤å¸Œè…ŠèŠ±ç“¶æ¨¡å‹çš„å¤šè§†è§’å›¾åƒã€‚æˆ‘æä¾›äº†ä»¥ä¸‹ 6 ä¸ªè§†è§’çš„å›¾ç‰‡ï¼š
front, back, left, right, top, bottom

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´å‡†ç¡®çš„captionæè¿°ï¼Œæ ¼å¼ç±»ä¼¼äºï¼š
"Athenian black-figure lekythos, c. 525â€“475 BCE, depicting Herakles and the boar; Marathon, Attica."

è¦æ±‚ï¼š
1. åŒ…å«å™¨å‹åç§°ï¼ˆå¦‚lekythos, amphora, hydriaç­‰ï¼‰
2. åŒ…å«åˆ¶ä½œæŠ€æ³•ï¼ˆå¦‚black-figure, red-figureï¼‰
3. åŒ…å«å¤§è‡´å¹´ä»£
4. ç®€è¦æè¿°ä¸»è¦è£…é¥°å†…å®¹
5. å¦‚æœèƒ½è¯†åˆ«ï¼ŒåŒ…å«å¯èƒ½çš„å‡ºåœŸåœ°ç‚¹
```

---

### 2. InternVL æè¿°ç”Ÿæˆå™¨

**æ–‡ä»¶ï¼š** `internvl.py`

**åŠŸèƒ½ï¼š** åŸºäº InternVL æ¨¡å‹ï¼Œåˆ†æå¤šè§†è§’å›¾åƒå¹¶ç”Ÿæˆç»¼åˆæè¿°

#### ä½¿ç”¨æ–¹æ³•

**æ‰¹é‡å¤„ç†ï¼š**
```bash
python internvl.py --input_dir ./data/multiview_images \
                   --output_dir ./data/captions \
                   --model_path ./models/OpenGVLab/InternVL3_5-4B
```

**å¤„ç†å•ä¸ªæ¨¡å‹ï¼š**
```bash
python internvl.py --single_model ./data/multiview_images/model1 \
                   --output_dir ./data/captions \
                   --model_path ./models/OpenGVLab/InternVL3_5-4B
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--input_dir` | åŒ…å«å¤šè§†è§’å›¾ç‰‡çš„è¾“å…¥ç›®å½• | `./data/multiview_images` |
| `--output_dir` | æè¿°è¾“å‡ºç›®å½• | `./data/captions` |
| `--model_path` | InternVLæ¨¡å‹è·¯å¾„ | `./models/OpenGVLab/InternVL3_5-4B` |
| `--single_model` | å¤„ç†å•ä¸ªæ¨¡å‹ç›®å½•ï¼ˆå¯é€‰ï¼‰ | `None` |

#### è¾“å‡ºæ ¼å¼

```json
[
  {
    "images": ["UUID_1_ac001001.jpg"],
    "caption": "...",
    "data_by": "internvl"
  }
]
```

è¾“å‡ºæ–‡ä»¶ï¼š
- `image_internvl.json` - ç”Ÿæˆçš„æè¿°
- `internvl_caption_generation_report.json` - å¤„ç†æŠ¥å‘Š

#### å¤šå¡æ¨ç†

InternVL æ”¯æŒå¤šå¡å¹¶è¡Œæ¨ç†ï¼š

```bash
# è®¾ç½®å¯è§GPU
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5

# ä¿®æ”¹è„šæœ¬ä¸­çš„ tp å‚æ•°
# tp=1 è¡¨ç¤ºå•å¡ï¼Œtp=6 è¡¨ç¤º6å¡å¹¶è¡Œ
```

---

## ğŸ“Š Caption è¯„ä¼°

### 1. å•æ¨¡å‹è¯„ä¼°

**æ–‡ä»¶ï¼š** `compare.py`

**åŠŸèƒ½ï¼š** è¯„ä¼°ç”Ÿæˆçš„ caption ä¸ ground truth çš„ç›¸ä¼¼åº¦ï¼Œè®¡ç®—å¤šä¸ªè¯„ä¼°æŒ‡æ ‡

#### ä½¿ç”¨æ–¹æ³•

```bash
python compare.py --generated ./data/captions/image_qwen2.5.json \
                  --ground_truth ./data/groundTruth.json \
                  --output results/qwen_eval.json
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--generated` | ç”Ÿæˆçš„caption JSONæ–‡ä»¶è·¯å¾„ | **å¿…éœ€** |
| `--ground_truth` | Ground truthæ–‡ä»¶è·¯å¾„ | `./data/groundTruth.json` |
| `--output` | è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ | è‡ªåŠ¨ç”Ÿæˆ |

#### è¯„ä¼°æŒ‡æ ‡

è„šæœ¬è®¡ç®—ä»¥ä¸‹è¯„ä¼°æŒ‡æ ‡ï¼š

##### 1. CLIP Score
- **è¯´æ˜**ï¼šè¡¡é‡ç”Ÿæˆcaptionä¸ground truthåœ¨CLIPåµŒå…¥ç©ºé—´ä¸­çš„ç›¸ä¼¼åº¦
- **èŒƒå›´**ï¼š0-1ï¼Œè¶Šé«˜è¶Šå¥½
- **æƒé‡**ï¼š25%

##### 2. FID Score
- **è¯´æ˜**ï¼šåŸºäºå¥å­åµŒå…¥çš„FrÃ©chet Inception Distance
- **èŒƒå›´**ï¼š0+ï¼Œè¶Šä½è¶Šå¥½
- **ç”¨é€”**ï¼šè¯„ä¼°ç”Ÿæˆåˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒçš„å·®å¼‚

##### 3. è¯­ä¹‰ç›¸ä¼¼åº¦
- **è¯´æ˜**ï¼šåŸºäºCLIPçš„è¯­ä¹‰ç›¸ä¼¼åº¦
- **èŒƒå›´**ï¼š0-1ï¼Œè¶Šé«˜è¶Šå¥½
- **æƒé‡**ï¼š25%

##### 4. R-Precision
- **R@1**ï¼šTop-1æ£€ç´¢å‡†ç¡®ç‡ï¼ˆæƒé‡5%ï¼‰
- **R@5**ï¼šTop-5æ£€ç´¢å‡†ç¡®ç‡ï¼ˆæƒé‡10%ï¼‰
- **R@10**ï¼šTop-10æ£€ç´¢å‡†ç¡®ç‡ï¼ˆæƒé‡20%ï¼‰

##### 5. è¯æ±‡é‡å ç›¸ä¼¼åº¦
- **è¯´æ˜**ï¼šåŸºäºJaccardç›¸ä¼¼åº¦çš„è¯æ±‡é‡å ç¨‹åº¦
- **èŒƒå›´**ï¼š0-1ï¼Œè¶Šé«˜è¶Šå¥½
- **æƒé‡**ï¼š15%

##### 6. ç»¼åˆè¯„åˆ†
- **è¯´æ˜**ï¼šæ‰€æœ‰æŒ‡æ ‡çš„åŠ æƒå¹³å‡åˆ†
- **èŒƒå›´**ï¼š0-1ï¼Œè¶Šé«˜è¶Šå¥½
- **å…¬å¼**ï¼š
  ```
  Overall Score = CLIP Score Ã— 0.25
                + Semantic Similarity Ã— 0.25
                + R@10 Ã— 0.20
                + Lexical Similarity Ã— 0.15
                + R@5 Ã— 0.10
                + R@1 Ã— 0.05
  ```

#### è¾“å‡ºç»“æœ

è„šæœ¬ç”Ÿæˆä¸¤ä¸ªæ–‡ä»¶ï¼š

**1. JSON ç»“æœæ–‡ä»¶** (`compare_model_name.json`)
```json
{
  "clip_score": 0.8234,
  "fid_score": 12.5678,
  "semantic_similarity": 0.7891,
  "r_at_1": 0.6500,
  "r_at_5": 0.8200,
  "r_at_10": 0.9100,
  "lexical_similarity": 0.4567,
  "overall_score": 0.7823,
  "metadata": {
    "total_pairs": 100,
    "generated_file": "...",
    "ground_truth_file": "...",
    "model_name": "qwen2.5"
  }
}
```

**2. æ–‡æœ¬æŠ¥å‘Š** (`compare_model_name.txt`)

åŒ…å«è¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```markdown
# Captionè¯„ä¼°æŠ¥å‘Š - qwen2.5

## åŸºæœ¬ä¿¡æ¯
- æ¨¡å‹åç§°: qwen2.5
- è¯„ä¼°æ ·æœ¬æ•°: 100
- ç”Ÿæˆæ–‡ä»¶: ./data/captions/image_qwen2.5.json
- Ground Truthæ–‡ä»¶: ./data/groundTruth.json

## è¯„ä¼°æŒ‡æ ‡

### 1. æ ¸å¿ƒæŒ‡æ ‡
- CLIP Score: 0.8234
- FID Score: 12.5678
- è¯­ä¹‰ç›¸ä¼¼åº¦: 0.7891

### 2. R-Precisionç»“æœ
- R@1: 65.00%
- R@5: 82.00%
- R@10: 91.00%

### 3. è¯æ±‡åŒ¹é…
- è¯æ±‡é‡å ç›¸ä¼¼åº¦: 0.4567

### 4. ç»¼åˆè¯„åˆ†
- æ•´ä½“è¯„åˆ†: 0.7823

## è¯„ä¼°æ€»ç»“
è¯¥æ¨¡å‹åœ¨captionç”Ÿæˆä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼š
1. CLIPç›¸ä¼¼åº¦: ä¼˜ç§€
2. è¯­ä¹‰ç†è§£: è‰¯å¥½
3. æ£€ç´¢æ€§èƒ½: ä¼˜ç§€
4. è¯æ±‡åŒ¹é…: ä¸€èˆ¬
5. æ•´ä½“è¯„åˆ†: è‰¯å¥½
```

---

### 2. æ‰¹é‡è¯„ä¼°

**æ–‡ä»¶ï¼š** `compare.sh`

**åŠŸèƒ½ï¼š** æ‰¹é‡è¯„ä¼°æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ¨¡å‹ç»“æœæ–‡ä»¶

#### ä½¿ç”¨æ–¹æ³•

```bash
# ä¿®æ”¹è„šæœ¬ä¸­çš„è·¯å¾„é…ç½®
CAPTION_DIR="./data/captions"
GROUND_TRUTH="./data/groundTruth.json"

# è¿è¡Œæ‰¹é‡è¯„ä¼°
./compare.sh
```

#### å¤„ç†æµç¨‹

1. æ‰«æ `CAPTION_DIR` ç›®å½•ä¸‹æ‰€æœ‰ `image_*.json` æ–‡ä»¶
2. è·³è¿‡ `groundTruth.json` æ–‡ä»¶
3. å¯¹æ¯ä¸ªæ–‡ä»¶è°ƒç”¨ `compare.py` è¿›è¡Œè¯„ä¼°
4. ç”Ÿæˆå„æ¨¡å‹çš„è¯¦ç»†æŠ¥å‘Š
5. æ±‡æ€»æ‰€æœ‰ç»“æœåˆ° `batch_evaluation_summary.json`
6. ç”Ÿæˆæ¨¡å‹å¯¹æ¯”è¡¨æ ¼

#### è¾“å‡ºç»“æœ

```
eval/
â”œâ”€â”€ compare_model1.json          # æ¨¡å‹1è¯¦ç»†ç»“æœ
â”œâ”€â”€ compare_model1.txt           # æ¨¡å‹1è¯„ä¼°æŠ¥å‘Š
â”œâ”€â”€ compare_model2.json          # æ¨¡å‹2è¯¦ç»†ç»“æœ
â”œâ”€â”€ compare_model2.txt           # æ¨¡å‹2è¯„ä¼°æŠ¥å‘Š
â”œâ”€â”€ batch_evaluation_summary.json  # æ‰¹é‡è¯„ä¼°æ±‡æ€»
â””â”€â”€ model_comparison_table.txt   # æ¨¡å‹å¯¹æ¯”è¡¨æ ¼
```

**æ¨¡å‹å¯¹æ¯”è¡¨æ ¼ç¤ºä¾‹ï¼š**
```
| Model Name | CLIP Score | Semantic Sim | R@10 | Overall Score |
|------------|------------|--------------|------|---------------|
| qwen2.5    | 0.8234     | 0.7891       | 0.91 | 0.7823        |
| internvl   | 0.8156     | 0.7654       | 0.89 | 0.7612        |
| gpt4v      | 0.8567     | 0.8123       | 0.93 | 0.8234        |
```

---

## ğŸ”§ ç¯å¢ƒé…ç½®

### ä¾èµ–å®‰è£…

```bash
pip install torch torchvision
pip install transformers
pip install sentence-transformers
pip install scipy numpy
pip install lmdeploy  # for InternVL
pip install modelscope  # for Qwen
pip install qwen-vl-utils
```

### æ¨¡å‹ä¸‹è½½

éœ€è¦ä¸‹è½½ä»¥ä¸‹æ¨¡å‹ï¼š

**Caption ç”Ÿæˆï¼š**
- Qwen2.5-VL-3B-Instruct æˆ– Qwen2.5-VL-7B-Instruct
- InternVL3_5-4B

**Caption è¯„ä¼°ï¼š**
- CLIP-ViT-Base-Patch32
- Sentence-Transformers all-mpnet-base-v2

### ç›®å½•ç»“æ„

å»ºè®®çš„ç›®å½•ç»“æ„ï¼š

```
eval/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ multiview_images/    # å¤šè§†è§’å›¾ç‰‡è¾“å…¥
â”‚   â”œâ”€â”€ captions/             # ç”Ÿæˆçš„captionè¾“å‡º
â”‚   â””â”€â”€ groundTruth.json      # Ground truthæ•°æ®
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ openai/
â”‚   â”‚   â””â”€â”€ clip-vit-base-patch32/
â”‚   â”œâ”€â”€ sentence-transformers/
â”‚   â”‚   â””â”€â”€ all-mpnet-base-v2/
â”‚   â”œâ”€â”€ OpenGVLab/
â”‚   â”‚   â””â”€â”€ InternVL3_5-4B/
â”‚   â””â”€â”€ Qwen2.5-VL-3B-Instruct/
â”œâ”€â”€ qwen.py
â”œâ”€â”€ internvl.py
â”œâ”€â”€ compare.py
â””â”€â”€ compare.sh
```

---

## ğŸ“Š å®Œæ•´è¯„ä¼°æµç¨‹

### æ­¥éª¤ 1: ç”Ÿæˆ Caption

```bash
# ä½¿ç”¨ Qwen2.5-VL ç”Ÿæˆ
python qwen.py --input_dir ./data/multiview_images \
               --output_dir ./data/captions

# ä½¿ç”¨ InternVL ç”Ÿæˆ
python internvl.py --input_dir ./data/multiview_images \
                   --output_dir ./data/captions
```

### æ­¥éª¤ 2: è¯„ä¼°å•ä¸ªæ¨¡å‹

```bash
# è¯„ä¼° Qwen2.5-VL ç»“æœ
python compare.py --generated ./data/captions/image_qwen2.5.json

# è¯„ä¼° InternVL ç»“æœ
python compare.py --generated ./data/captions/image_internvl.json
```

### æ­¥éª¤ 3: æ‰¹é‡è¯„ä¼°æ‰€æœ‰æ¨¡å‹

```bash
./compare.sh
```

### æ­¥éª¤ 4: åˆ†æç»“æœ

æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶ï¼š
```bash
# æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š
cat compare_qwen2.5.txt

# æŸ¥çœ‹å¯¹æ¯”è¡¨æ ¼
cat model_comparison_table.txt

# æŸ¥çœ‹JSONç»“æœ
cat compare_qwen2.5.json | jq
```

---

## ğŸ’¡ ä½¿ç”¨æŠ€å·§

### 1. æé«˜ç”Ÿæˆè´¨é‡

**ä¼˜åŒ–æç¤ºè¯ï¼š**
- åœ¨è„šæœ¬ä¸­ä¿®æ”¹æç¤ºè¯æ¨¡æ¿
- æ·»åŠ æ›´å¤šç¤ºä¾‹å’Œçº¦æŸ
- è°ƒæ•´ç”Ÿæˆå‚æ•°ï¼ˆtemperature, top_pç­‰ï¼‰

**ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ï¼š**
```bash
# ä½¿ç”¨7Bæ¨¡å‹æ›¿ä»£3B
python qwen.py --model_path ./models/Qwen2.5-VL-7B-Instruct
```

### 2. åŠ é€Ÿæ¨ç†

**ä½¿ç”¨å¤šå¡å¹¶è¡Œï¼š**
```bash
# InternVL å¤šå¡æ¨ç†
export CUDA_VISIBLE_DEVICES=0,1,2,3
# ä¿®æ”¹è„šæœ¬ä¸­ tp=4
```

**æ‰¹é‡å¤„ç†ï¼š**
```bash
# ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å›¾ç‰‡
python qwen.py --input_dir ./data/multiview_images
```

### 3. è‡ªå®šä¹‰è¯„ä¼°

**ä¿®æ”¹è¯„ä¼°æƒé‡ï¼š**

åœ¨ `compare.py` ä¸­ä¿®æ”¹ç»¼åˆè¯„åˆ†è®¡ç®—ï¼š
```python
results["overall_score"] = (
    results.get("clip_score", 0) * 0.30 +      # è°ƒæ•´æƒé‡
    results.get("semantic_similarity", 0) * 0.30 +
    results.get("r_at_10", 0) * 0.20 +
    results.get("lexical_similarity", 0) * 0.20
)
```

**æ·»åŠ æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼š**

åœ¨ `CaptionEvaluator` ç±»ä¸­æ·»åŠ æ–°æ–¹æ³•ï¼š
```python
def calculate_custom_metric(self, generated, ground_truth):
    # å®ç°è‡ªå®šä¹‰è¯„ä¼°é€»è¾‘
    return score
```

---

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. CUDA Out of Memory**
```bash
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
python qwen.py --model_path ./models/Qwen2.5-VL-3B-Instruct

# å‡å°‘æ‰¹å¤„ç†å¤§å°
# åœ¨è„šæœ¬ä¸­ä¿®æ”¹ batch_size
```

**2. æ¨¡å‹åŠ è½½å¤±è´¥**
```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -la ./models/

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
du -sh ./models/Qwen2.5-VL-3B-Instruct/

# é‡æ–°ä¸‹è½½æ¨¡å‹
```

**3. è¯„ä¼°æŒ‡æ ‡ä¸º0**
```bash
# æ£€æŸ¥CLIPæ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½
# æŸ¥çœ‹æ—¥å¿—è¾“å‡º

# æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®
cat ./data/captions/image_model.json | jq
```

**4. å›¾ç‰‡æ–‡ä»¶åä¸åŒ¹é…**
```bash
# æ£€æŸ¥æ–‡ä»¶åæ ¼å¼
# ç¡®ä¿ç¬¦åˆ UUID_æ•°å­—_ac001001.jpg æ ¼å¼

# æŸ¥çœ‹æå–çš„å›¾ç‰‡å
# åœ¨è„šæœ¬ä¸­æ·»åŠ è°ƒè¯•è¾“å‡º
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### ç”Ÿæˆé€Ÿåº¦

| æ¨¡å‹ | å•å¼ è€—æ—¶ | 100å¼ è€—æ—¶ | GPUæ˜¾å­˜ |
|------|---------|----------|---------|
| Qwen2.5-VL-3B | ~5s | ~8min | ~12GB |
| Qwen2.5-VL-7B | ~8s | ~13min | ~24GB |
| InternVL3_5-4B | ~6s | ~10min | ~16GB |

### è¯„ä¼°é€Ÿåº¦

| æ ·æœ¬æ•° | è€—æ—¶ | GPUæ˜¾å­˜ |
|--------|------|---------|
| 100 | ~2min | ~4GB |
| 500 | ~8min | ~4GB |
| 1000 | ~15min | ~4GB |

---

## ğŸ“š å‚è€ƒèµ„æº

- [Qwen2.5-VL æ–‡æ¡£](https://github.com/QwenLM/Qwen2-VL)
- [InternVL æ–‡æ¡£](https://github.com/OpenGVLab/InternVL)
- [CLIP è®ºæ–‡](https://arxiv.org/abs/2103.00020)
- [Sentence-Transformers](https://www.sbert.net/)

---

## ğŸ“ æ•°æ®æ ¼å¼è¯´æ˜

### Ground Truth æ ¼å¼

```json
[
  {
    "images": ["UUID_1_ac001001.jpg"],
    "caption": "Athenian black-figure lekythos, c. 525â€“475 BCE, depicting Herakles and the boar; Marathon, Attica."
  },
  {
    "images": ["UUID_2_ac001001.jpg"],
    "caption": "..."
  }
]
```

### ç”Ÿæˆç»“æœæ ¼å¼

```json
[
  {
    "images": ["UUID_1_ac001001.jpg"],
    "caption": "ç”Ÿæˆçš„æè¿°æ–‡æœ¬",
    "data_by": "æ¨¡å‹åç§°"
  }
]
```

---

**ğŸ’¡ æç¤º**: å»ºè®®å…ˆåœ¨å°æ•°æ®é›†ä¸Šæµ‹è¯•å®Œæ•´æµç¨‹ï¼Œç¡®è®¤æ— è¯¯åå†è¿›è¡Œå¤§è§„æ¨¡è¯„ä¼°ã€‚
